# Topological Characterization of Information Loss

> *"Information loss isn't just a number ‚Äî it has shape, location, and structure."*

When we transform data between modalities, we lose information. But saying "70% lost" 
misses the rich structure of *what* was lost, *where* it was lost, and *how* the 
remaining information is shaped.

This chapter develops intuition for characterizing information loss topologically.

---

## The Problem with Scalar Loss

Consider encoding an image to an embedding:

```
1024√ó1024√ó3 image ‚Üí 768-dimensional embedding
```

A naive view: "We went from 3M numbers to 768. That's 99.97% compression."

But this misses everything important:
- Did we lose **spatial** detail (where things are)?
- Did we lose **semantic** detail (what things mean)?
- Did we lose **relational** detail (how things connect)?
- Is the loss **uniform** or concentrated in certain regions?
- What **structure** does the preserved information have?

Topology gives us tools to answer these questions.

---

## Part 1: What KIND of Information Was Lost?

### The Loss Type Taxonomy

Different transformations lose different *kinds* of information:

| Loss Type | What's Lost | Example |
|-----------|-------------|---------|
| **Spatial** | Position, location, arrangement | Image ‚Üí embedding loses pixel positions |
| **Temporal** | Sequence, timing, dynamics | Audio ‚Üí embedding loses time structure |
| **Semantic** | Meaning, concepts, categories | Text ‚Üí tokens loses word boundaries |
| **Relational** | Connections, dependencies | Graph ‚Üí embedding loses edge structure |
| **Structural** | Topology, shape, connectivity | 3D mesh ‚Üí point cloud loses faces |
| **Statistical** | Distribution, variance, moments | Quantization loses precision |

### Visualizing Loss Types

**Spatial Loss** (Image ‚Üí Embedding):
```
Original:                    After:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              
‚îÇ üê±    üå≥    ‚îÇ              ‚Üí [0.2, -0.5, 0.8, ...]
‚îÇ      üè†    ‚îÇ              
‚îÇ  üöó       ‚îÇ              768 numbers, no positions
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              
```
The embedding knows "cat, tree, house, car" but not where they are.

**Relational Loss** (Knowledge Graph ‚Üí Embedding):
```
Original:                    After:
Einstein ‚îÄ‚îÄwrote‚îÄ‚îÄ‚Üí Relativity
    ‚îÇ                        ‚Üí [0.3, 0.1, -0.7, ...]
    ‚îî‚îÄ‚îÄborn_in‚îÄ‚îÄ‚Üí Ulm       
                             The relationships are implicit, not explicit
```

**Temporal Loss** (Audio ‚Üí Spectrogram ‚Üí Embedding):
```
Original: "Hello" spoken over 0.5 seconds
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ H  e  l  l  o    ‚îÇ (time ‚Üí)
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         
After:   [0.4, -0.2, 0.9, ...] ‚Äî no time axis
```

### Why This Matters

If you're building a system that needs spatial reasoning, you need to know that your
embedding step loses spatial information. The loss *type* tells you what downstream
tasks will struggle.

---

## Part 2: WHERE Was Information Lost?

### Affected Dimensions

When we project from high to low dimensions, not all input dimensions are treated equally.

**Example: PCA on Images**

```python
# 1000 images, each 64√ó64 = 4096 dimensions
# PCA to 100 dimensions

# The first few principal components capture:
# - Overall brightness (PC1)
# - Left-right gradient (PC2)  
# - Top-bottom gradient (PC3)
# ...

# The last components (discarded) captured:
# - High-frequency texture
# - Fine edge details
# - Noise
```

The loss is *localized* in the high-frequency components.

### Affected Indices

For structured data, we can track exactly which elements were affected:

```python
# Original text: "The quick brown fox jumps over the lazy dog"
# After tokenization: [464, 2068, 7586, 21831, 18045, 625, 262, 16931, 3290]

# After embedding, we lose:
# - Word boundaries (indices where words start/end)
# - Character-level detail within tokens
# - Punctuation nuances
```

### The Kernel and Cokernel

In linear algebra terms:
- **Kernel**: What gets mapped to zero (completely lost)
- **Cokernel**: What can't be reached (information that can't be represented)

For a transformation T: A ‚Üí B:
- ker(T) = {a ‚àà A : T(a) = 0} ‚Äî inputs that produce no output
- coker(T) = B / im(T) ‚Äî outputs that no input produces

**Example**: Grayscale conversion
```
RGB ‚Üí Grayscale

Kernel: Color differences (red-green, blue-yellow)
        [1, 0, 0] - [0, 1, 0] = [1, -1, 0] ‚Üí 0 (same gray)
        
Cokernel: Nothing (every grayscale value is reachable)
```

---

## Part 3: The SHAPE of What Remains (Betti Numbers)

### Counting Holes at Different Dimensions

Betti numbers are topological invariants that count "holes":

| Betti Number | What It Counts | Intuition |
|--------------|----------------|-----------|
| **b‚ÇÄ** | Connected components | "How many separate pieces?" |
| **b‚ÇÅ** | 1-dimensional holes | "How many loops/tunnels?" |
| **b‚ÇÇ** | 2-dimensional holes | "How many enclosed voids?" |

### Example: Point Cloud Topology

Consider a point cloud sampled from different shapes:

**Solid disk** (b‚ÇÄ=1, b‚ÇÅ=0):
```
    ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
  ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
  ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
  ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
    ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
```
One connected piece, no holes.

**Circle/ring** (b‚ÇÄ=1, b‚ÇÅ=1):
```
    ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
  ‚Ä¢           ‚Ä¢
  ‚Ä¢           ‚Ä¢
  ‚Ä¢           ‚Ä¢
    ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
```
One connected piece, one hole in the middle.

**Two separate circles** (b‚ÇÄ=2, b‚ÇÅ=2):
```
  ‚Ä¢ ‚Ä¢ ‚Ä¢     ‚Ä¢ ‚Ä¢ ‚Ä¢
‚Ä¢       ‚Ä¢ ‚Ä¢       ‚Ä¢
‚Ä¢       ‚Ä¢ ‚Ä¢       ‚Ä¢
  ‚Ä¢ ‚Ä¢ ‚Ä¢     ‚Ä¢ ‚Ä¢ ‚Ä¢
```
Two connected pieces, each with a hole.

### How Transformations Change Topology

**Embedding typically reduces Betti numbers:**

```
Original data:                 After embedding:
b‚ÇÄ = 1000 (many clusters)  ‚Üí   b‚ÇÄ = 1 (single manifold)
b‚ÇÅ = 50 (loops in data)    ‚Üí   b‚ÇÅ = 0 (loops collapsed)
b‚ÇÇ = 5 (voids)             ‚Üí   b‚ÇÇ = 0 (voids filled)
```

The embedding "smooths out" the topological structure.

**Entity extraction partially recovers structure:**

```
Embedding:                     After extraction:
b‚ÇÄ = 1 (single blob)       ‚Üí   b‚ÇÄ = 15 (15 entities)
b‚ÇÅ = 0 (no loops)          ‚Üí   b‚ÇÅ = 3 (3 relationship cycles)
```

Extracting entities creates discrete components; relationships create cycles.

### Persistent Homology: Tracking Features Across Scales

Not all topological features are equally important. **Persistent homology** tracks
which features survive as we vary a scale parameter.

```
Scale:  0.1    0.5    1.0    2.0    5.0
        
b‚ÇÄ:     100    50     20     5      1
        ‚Üì      ‚Üì      ‚Üì      ‚Üì      ‚Üì
        noise  small  medium large  all
               clusters      clusters connected
```

Features that persist across many scales are "real"; features that appear and
disappear quickly are noise.

**Persistence diagram:**
```
Death
  ‚îÇ    
5 ‚îÇ         √ó           (long-lived feature)
  ‚îÇ    
2 ‚îÇ    √ó √ó              (medium-lived)
  ‚îÇ  √ó √ó √ó √ó            (short-lived = noise)
1 ‚îÇ√ó √ó √ó √ó √ó √ó
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Birth
     0  1  2  3  4
```

Points far from the diagonal are significant features.

---

## Part 4: The Sheaf Perspective on Loss

### Restriction Maps and Their Kernels

In sheaf terms, a transformation is a **restriction map**:

```
œÅ: F(U) ‚Üí F(V)    where V ‚äÜ U
```

The kernel of œÅ is the information that's "invisible" from V:

```
ker(œÅ) = {s ‚àà F(U) : œÅ(s) = 0}
```

**Example**: Image ‚Üí Embedding

```
F(image) = ‚Ñù^(1024√ó1024√ó3)    (all possible images)
F(embedding) = ‚Ñù^768           (all possible embeddings)

œÅ = CLIP encoder

ker(œÅ) ‚âà {images that map to the zero vector}
       ‚âà {adversarial noise patterns}
```

More usefully, we care about the **approximate kernel**: images that map to
*similar* embeddings.

### Cohomology of the Transformation

The cohomology groups measure the "failure" of the transformation:

- **H‚Å∞(œÅ)**: Global sections that survive the transformation
- **H¬π(œÅ)**: Obstructions ‚Äî information that can't be recovered

When H¬π ‚â† 0, there's information loss that creates inconsistency.

### The Exact Sequence

For a transformation T: A ‚Üí B, we have:

```
0 ‚Üí ker(T) ‚Üí A ‚Üí B ‚Üí coker(T) ‚Üí 0
```

This tells us:
- ker(T): What's completely lost
- im(T): What's preserved (but possibly transformed)
- coker(T): What can't be represented

**For embeddings:**
```
0 ‚Üí [high-freq details] ‚Üí Image ‚Üí Embedding ‚Üí [unreachable embeddings] ‚Üí 0
         ker                         im              coker
```

---

## Part 5: Measuring Loss in Practice

### The TopologicalLossCharacterization Structure

In ModalSheaf, we capture loss with:

```python
@dataclass
class TopologicalLossCharacterization:
    # Scalar summary
    total_loss: float  # 0.0 to 1.0
    
    # Breakdown by type
    loss_regions: List[LossRegion]  # Each has type, magnitude, location
    
    # What's preserved
    preserved_dimensions: int       # Effective dimensionality
    preserved_betti: Tuple[int, ...]  # Topological invariants
    
    # Distribution of loss
    loss_entropy: float  # High = uniform, Low = concentrated
    
    # Confidence
    is_measured: bool    # Computed from data, or estimated?
    confidence: float    # How sure are we?
```

### Computing Betti Numbers

For point cloud data, use persistent homology:

```python
import numpy as np
from ripser import ripser  # TDA library

def compute_betti(points, max_dim=2):
    """Compute Betti numbers of a point cloud."""
    result = ripser(points, maxdim=max_dim)
    
    betti = []
    for dim in range(max_dim + 1):
        # Count features that persist significantly
        dgm = result['dgms'][dim]
        persistence = dgm[:, 1] - dgm[:, 0]
        significant = np.sum(persistence > 0.1)  # Threshold
        betti.append(significant)
    
    return tuple(betti)
```

### Comparing Before and After

```python
def measure_topological_loss(original, transformed, transform_fn):
    """Measure how topology changes through a transformation."""
    
    # Compute Betti numbers before
    betti_before = compute_betti(original)
    
    # Apply transformation
    result = transform_fn(original)
    
    # Compute Betti numbers after
    betti_after = compute_betti(transformed)
    
    # Measure change
    loss_regions = []
    
    # b‚ÇÄ change (connected components)
    if betti_before[0] != betti_after[0]:
        loss_regions.append(LossRegion(
            loss_type=LossType.STRUCTURAL,
            magnitude=abs(betti_before[0] - betti_after[0]) / max(betti_before[0], 1),
            description=f"Components: {betti_before[0]} ‚Üí {betti_after[0]}"
        ))
    
    # b‚ÇÅ change (loops)
    if betti_before[1] != betti_after[1]:
        loss_regions.append(LossRegion(
            loss_type=LossType.RELATIONAL,
            magnitude=abs(betti_before[1] - betti_after[1]) / max(betti_before[1], 1),
            description=f"Loops: {betti_before[1]} ‚Üí {betti_after[1]}"
        ))
    
    return TopologicalLossCharacterization(
        total_loss=compute_total_loss(betti_before, betti_after),
        loss_regions=loss_regions,
        preserved_betti=betti_after,
        is_measured=True
    )
```

---

## Part 6: Intuitive Examples

### Example 1: Text ‚Üí Embedding ‚Üí Entities ‚Üí Text

Let's trace topology through a full pipeline:

**Original text:**
```
"Einstein was born in Ulm. He developed relativity. 
 Relativity changed physics. Physics explains the universe."
```

**Topology of original:**
- b‚ÇÄ = 1 (one connected document)
- b‚ÇÅ = 1 (circular reference: Einstein ‚Üí relativity ‚Üí physics ‚Üí universe ‚Üí ?)

**After embedding (768-dim vector):**
- b‚ÇÄ = 1 (single point in embedding space)
- b‚ÇÅ = 0 (no loops ‚Äî it's just a point)

**Loss:** The circular narrative structure is destroyed.

**After entity extraction:**
```
Einstein ‚îÄ‚îÄborn_in‚îÄ‚îÄ‚Üí Ulm
    ‚îÇ
    ‚îî‚îÄ‚îÄdeveloped‚îÄ‚îÄ‚Üí Relativity ‚îÄ‚îÄchanged‚îÄ‚îÄ‚Üí Physics ‚îÄ‚îÄexplains‚îÄ‚îÄ‚Üí Universe
```
- b‚ÇÄ = 5 (five entities)
- b‚ÇÅ = 0 (no cycles in this graph)

**After text generation:**
```
"Einstein was born in Ulm and developed relativity, 
 which changed physics that explains the universe."
```
- b‚ÇÄ = 1 (one document again)
- b‚ÇÅ = 0 (linear narrative, no cycles)

**What was lost:** The original had an implicit cycle (universe connects back to
Einstein as a physicist). The reconstruction is linear.

### Example 2: Image ‚Üí Patches ‚Üí Embedding

**Original image (224√ó224√ó3):**
- b‚ÇÄ = 1 (one connected image)
- b‚ÇÅ = 3 (three "holes" ‚Äî e.g., spaces between objects)
- Spatial structure: 224√ó224 grid

**After patching (14√ó14 patches of 16√ó16):**
- b‚ÇÄ = 196 (196 separate patches)
- b‚ÇÅ = 0 (patches don't form loops)
- Spatial structure: 14√ó14 grid (coarser)

**Loss:** Local connectivity within patches preserved, but global holes destroyed.

**After embedding (768-dim per patch, then averaged):**
- b‚ÇÄ = 1 (single embedding)
- b‚ÇÅ = 0 (no structure)
- Spatial structure: None

**Loss:** All spatial and topological structure gone.

### Example 3: Knowledge Graph ‚Üí Embedding ‚Üí Knowledge Graph

**Original graph:**
```
    A ‚Üê‚îÄ‚îÄ‚Üí B
    ‚Üë      ‚Üì
    D ‚Üê‚îÄ‚îÄ‚Üí C
```
- b‚ÇÄ = 1 (connected)
- b‚ÇÅ = 1 (one cycle: A‚ÜíB‚ÜíC‚ÜíD‚ÜíA)

**After graph embedding (e.g., node2vec):**
- Each node ‚Üí 64-dim vector
- Graph structure ‚Üí implicit in distances

**After reconstruction (from embeddings):**
```
    A ‚îÄ‚îÄ‚îÄ‚Üí B
    ‚Üë      ‚Üì
    D ‚Üê‚îÄ‚îÄ‚îÄ C
```
- b‚ÇÄ = 1 (still connected)
- b‚ÇÅ = 1 (cycle preserved!)

**In this case:** The topology was preserved because the embedding captured
the cyclic structure. But edge directions might be lost.

---

## Part 7: Practical Guidelines

### When to Care About Topological Loss

| Task | Critical Loss Types | Why |
|------|---------------------|-----|
| Object detection | Spatial | Need to know *where* things are |
| Sentiment analysis | Semantic | Need meaning, not structure |
| Relationship extraction | Relational | Need connections between entities |
| Time series forecasting | Temporal | Need sequence structure |
| Graph neural networks | Structural | Need topology of connections |

### Choosing Transforms to Minimize Critical Loss

If your task needs spatial information:
- Avoid global pooling (destroys position)
- Use position-preserving architectures (CNNs, ViTs with position embeddings)
- Track spatial loss explicitly

If your task needs relational information:
- Avoid bag-of-words (destroys relationships)
- Use graph-aware embeddings
- Preserve edge structure

### Warning Users About Loss

```python
def warn_if_critical_loss(loss: TopologicalLossCharacterization, task: str):
    """Warn if the loss type is critical for the task."""
    
    critical_types = {
        "object_detection": [LossType.SPATIAL],
        "sentiment": [LossType.SEMANTIC],
        "relation_extraction": [LossType.RELATIONAL],
        "forecasting": [LossType.TEMPORAL],
    }
    
    critical = critical_types.get(task, [])
    
    for region in loss.loss_regions:
        if region.loss_type in critical and region.magnitude > 0.3:
            warnings.warn(
                f"‚ö†Ô∏è High {region.loss_type.name} loss ({region.magnitude:.0%}) "
                f"may impact {task} performance. {region.description}"
            )
```

---

## Summary

### Key Concepts

1. **Loss has TYPE**: Spatial, temporal, semantic, relational, structural
2. **Loss has LOCATION**: Which dimensions, indices, or regions are affected
3. **Loss has SHAPE**: Betti numbers capture topological structure
4. **Loss can be MEASURED**: Not just estimated, but computed from actual data

### The Topological View

| Before | After | What Changed |
|--------|-------|--------------|
| b‚ÇÄ = many | b‚ÇÄ = 1 | Clusters merged |
| b‚ÇÅ = some | b‚ÇÅ = 0 | Loops collapsed |
| b‚ÇÇ = few | b‚ÇÇ = 0 | Voids filled |

### In ModalSheaf

```python
result = transform(data)

# Not just this:
print(f"Loss: {result.loss.total_loss:.0%}")

# But also this:
print(f"Dominant loss: {result.loss.dominant_loss_type().name}")
print(f"Preserved topology: b‚ÇÄ={result.loss.preserved_betti[0]}")
for region in result.loss.loss_regions:
    print(f"  {region.loss_type.name}: {region.magnitude:.0%}")
    print(f"    {region.description}")
```

---

## Further Reading

### Intuitive
1. **Ghrist, "Elementary Applied Topology"** ‚Äî Free PDF, beautifully illustrated
2. **Carlsson, "Topology and Data"** ‚Äî The foundational TDA paper, very readable

### Applied
3. **Robinson, "Topological Signal Processing"** ‚Äî Sheaves for signal processing
4. **Chazal & Michel, "Introduction to TDA"** ‚Äî Modern, practical

### Deep
5. **Curry, "Sheaves, Cosheaves and Applications"** ‚Äî Localization and loss
6. **Edelsbrunner & Harer, "Computational Topology"** ‚Äî Algorithms for Betti numbers

### Software
7. **Ripser** ‚Äî Fast persistent homology: `pip install ripser`
8. **GUDHI** ‚Äî Comprehensive TDA library: `pip install gudhi`
9. **giotto-tda** ‚Äî TDA for machine learning: `pip install giotto-tda`

---

## Exercises

1. **Compute Betti numbers** for a point cloud sampled from a torus. Verify b‚ÇÄ=1, b‚ÇÅ=2, b‚ÇÇ=1.

2. **Track topology** through an image ‚Üí CLIP ‚Üí image reconstruction pipeline. What's lost?

3. **Design a transform** that preserves b‚ÇÅ (loops) while reducing dimensionality.

4. **Measure loss types** for your favorite embedding model. Is it mostly spatial, semantic, or relational?
